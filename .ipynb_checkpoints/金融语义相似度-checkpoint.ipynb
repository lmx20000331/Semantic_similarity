{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 采样\n",
    "2. 混合精度训练\n",
    "3. 持续预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting torch==1.6.0\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8MB 8.4MB/s eta 0:00:013    |███▍                            | 79.1MB 10.1MB/s eta 0:01:07     |█████████████▉                  | 323.1MB 11.6MB/s eta 0:00:37     |█████████████████▎              | 404.9MB 11.2MB/s eta 0:00:31     |██████████████████████████▏     | 611.6MB 9.7MB/s eta 0:00:15     |████████████████████████████▎   | 661.1MB 10.6MB/s eta 0:00:09     |███████████████████████████████ | 727.0MB 7.8MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch==1.6.0) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch==1.6.0) (0.18.0)\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "Successfully installed torch-1.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting torchvision==0.7.0\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/4d/b5/60d5eb61f1880707a5749fea43e0ec76f27dfe69391cdec953ab5da5e676/torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9MB 17.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torchvision==0.7.0) (1.19.1)\n",
      "Requirement already satisfied: torch==1.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torchvision==0.7.0) (1.6.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torchvision==0.7.0) (7.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from torch==1.6.0->torchvision==0.7.0) (0.18.0)\n",
      "Installing collected packages: torchvision\n",
      "  Found existing installation: torchvision 0.5.0\n",
      "    Uninstalling torchvision-0.5.0:\n",
      "      Successfully uninstalled torchvision-0.5.0\n",
      "Successfully installed torchvision-0.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torchvision==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "config = {\n",
    "        'train_file_path': 'data/data100821/train.json',\n",
    "        'dev_file_path': 'data/data100821/dev.json',\n",
    "        'test_file_path': 'data/data100821/test.json',\n",
    "        'output_path': '.',\n",
    "        'model_path': 'data/data94445',\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 1,\n",
    "        'max_seq_len': 64,\n",
    "        'learning_rate': 2e-5,\n",
    "        'eps': 0.1,\n",
    "        'alpha': 0.3,\n",
    "        'adv': 'fgm',\n",
    "        'warmup_ratio': 0.05,\n",
    "        'weight_decay': 0.01,\n",
    "        'use_bucket': True,\n",
    "        'bucket_multiplier': 200,\n",
    "        'device': 'cuda',\n",
    "        'n_gpus': 0,\n",
    "        'use_amp': True,  # 只针对有 tensor core 的gpu有效\n",
    "        'logging_step': 400,\n",
    "        'ema_start_step': 500,\n",
    "        'ema_start': False,\n",
    "        'seed': 2021\n",
    "    }\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    config['device'] = 'cpu'\n",
    "else:\n",
    "    config['n_gpus'] = torch.cuda.device_count()\n",
    "    config['batch_size'] *= config['n_gpus']\n",
    "\n",
    "if not os.path.exists(config['output_path']):\n",
    "    os.makedirs((config['output_path']))\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting transformers==4.0.1\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 12.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (0.0.43)\n",
      "Collecting packaging (from transformers==4.0.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/3c/77/e2362b676dc5008d81be423070dd9577fa03be5da2ba1105811900fda546/packaging-21.0-py3-none-any.whl (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 37.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (1.19.1)\n",
      "Collecting filelock (from transformers==4.0.1)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Collecting tokenizers==0.9.4 (from transformers==4.0.1)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 32.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (4.45.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (2.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (2020.7.14)\n",
      "Requirement already satisfied: click in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (7.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->transformers==4.0.1) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (2.8)\n",
      "Installing collected packages: packaging, filelock, tokenizers, transformers\n",
      "Successfully installed filelock-3.0.12 packaging-21.0 tokenizers-0.9.4 transformers-4.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "def parse_data(path, data_type='train'):\n",
    "    sentence_a = []\n",
    "    sentence_b = []\n",
    "    labels = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
    "            line = json.loads(line)\n",
    "            sentence_a.append(line['sentence1'])\n",
    "            sentence_b.append(line['sentence2'])\n",
    "            if data_type != 'test':\n",
    "                labels.append(int(line['label']))\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns=['text_a', 'text_b', 'labels'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs defaultdict(list)\n",
    "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
    "    # add_special_tokens [CLS] [SEP]\n",
    "    # return_token_type_ids 该词属于sentence_a or sentence_b. \n",
    "    # return_attention_mask pad=0, 不是pad的部分标为1， 是pad标为0. \n",
    "    inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens=True,\n",
    "                          return_token_type_ids=True, return_attention_mask=True)\n",
    "    inputs['input_ids'].append(inputs_dict['input_ids'])\n",
    "    inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
    "    inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
    "    inputs['labels'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def read_data(config, tokenizer):\n",
    "    train_df = parse_data(config['train_file_path'], data_type='train')\n",
    "    dev_df = parse_data(config['dev_file_path'], data_type='dev')\n",
    "    test_df = parse_data(config['test_file_path'], data_type='test')\n",
    "\n",
    "    data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
    "    # 保存BERT的输入\n",
    "    processed_data ={}\n",
    "\n",
    "    for data_type, df in data_df.items():\n",
    "        inputs = defaultdict(list)\n",
    "        for i, row in tqdm(df.iterrows(), desc=f'Preprocessing {data_type} data', total=len(df)):\n",
    "            label = row[2]\n",
    "            sentence_a, sentence_b = row[0], row[1]\n",
    "            build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
    "        \n",
    "        processed_data[data_type] = inputs\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 232835.67it/s]\n",
      "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 281406.77it/s]\n",
      "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 286288.72it/s]\n",
      "Preprocessing train data: 100%|██████████| 34334/34334 [00:16<00:00, 2029.87it/s]\n",
      "Preprocessing dev data: 100%|██████████| 4316/4316 [00:02<00:00, 2051.48it/s]\n",
      "Preprocessing test data: 100%|██████████| 3861/3861 [00:01<00:00, 2081.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config['model_path'])\n",
    "dt = read_data(config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 6010, 6009, 955, 1446, 5023, 7583, 6820, 3621, 1377, 809, 2940, 2768, 1044, 2622, 1400, 3315, 1408, 102, 955, 1446, 3300, 1044, 2622, 1168, 3309, 6820, 3315, 1408, 102]\n"
     ]
    }
   ],
   "source": [
    "print(dt['train']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class AFQMCDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        super(AFQMCDataset, self).__init__()\n",
    "        self.data_dict = data_dict\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = (self.data_dict['input_ids'][index], self.data_dict['token_type_ids'][index],\n",
    "                self.data_dict['attention_mask'][index], self.data_dict['labels'][index])\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    def __init__(self, max_seq_len, tokenizer):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
    "        input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype=torch.long)\n",
    "        token_type_ids = torch.zeros_like(input_ids)\n",
    "        attention_mask = torch.zeros_like(input_ids)\n",
    "\n",
    "        for i in range(len(input_ids_list)):\n",
    "            seq_len = len(input_ids_list[i])\n",
    "\n",
    "            if seq_len <=max_seq_len:\n",
    "                input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype=torch.long)\n",
    "                token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype=torch.long)\n",
    "                attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype=torch.long)\n",
    "            \n",
    "            else:\n",
    "                # input_ids 最后一位放上一个特殊的token\n",
    "                input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len-1] + [self.tokenizer.sep_token_id], \n",
    "                                            dtype=torch.long)\n",
    "                # token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len-1] + [self.tokenizer.sep_token_id], \n",
    "                #                             dtype=torch.long)\n",
    "                # attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len-1] + [self.tokenizer.sep_token_id], \n",
    "                #                             dtype=torch.long)\n",
    "                token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype=torch.long)\n",
    "                attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype=torch.long)\n",
    "        \n",
    "        labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "        return input_ids, token_type_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
    "        cur_max_seq_len = max(len(input_id) for input_id in input_ids_list)\n",
    "        max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, \n",
    "                                                                                  token_type_ids_list, attention_mask_list,\n",
    "                                                                                  labels_list, max_seq_len)\n",
    "        data_dict = {\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "        return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = Collator(config['max_seq_len'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![build_dataloader](https://img-blog.csdnimg.cn/ea1002a506ee4eb78e9cfb1bc4c0595c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataloader](https://img-blog.csdnimg.cn/b80cee8a1c7d49b79e7b80cc81150d66.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所有采样器都继承自Sampler这个类\n",
    "# 每个Sampler子类都要实现__iter__方法【迭代数据集example索引的方法】，以及返回迭代器长度的__len__方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sampler](https://img-blog.csdnimg.cn/1c40aedade9f40a493b4df97d0c1def0.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sequentialsampler](https://img-blog.csdnimg.cn/9e8ee018cea84729ac6b5742395d8ea2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在初始化时拿到数据集data_source， 按顺序对元素进行采样，每次只返回一个索引值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[14,  3, 15,  5],\n",
      "         [ 2, 20,  9, 16],\n",
      "         [19, 21,  7, 17]],\n",
      "\n",
      "        [[22, 12, 23,  8],\n",
      "         [ 6, 10, 18,  1],\n",
      "         [ 4, 13, 11,  0]]])\n",
      "<torch.utils.data.sampler.SequentialSampler object at 0x7f7118f0ded0>\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# (2,3,4) batch_size:2 seq_len=3, embedding_dim=4，每个 batch 有2条数据，每个句子包含3个词， 每个词的维度是4\n",
    "a = torch.randperm(24).reshape((2,3,4))\n",
    "print(a)\n",
    "b = torch.utils.data.SequentialSampler(a)\n",
    "print(b)\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replacement : True 表示可以重复采样\n",
    "# num_samples:  指定采样的数量\n",
    "PS:当使用replacement=False，不应制定num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![randomsampler](https://img-blog.csdnimg.cn/9d2e2afdbe4d4df4aee3102e46054650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[54, 49, 14, 52],\n",
      "         [19, 34, 26, 29],\n",
      "         [15, 45, 43, 59]],\n",
      "\n",
      "        [[56, 27, 44, 22],\n",
      "         [25, 38, 33, 51],\n",
      "         [30, 47, 10,  9]],\n",
      "\n",
      "        [[ 1, 53,  7,  0],\n",
      "         [50, 28, 39,  6],\n",
      "         [11, 17, 58, 48]],\n",
      "\n",
      "        [[ 2, 46,  5, 12],\n",
      "         [24, 36,  4, 16],\n",
      "         [ 3, 31, 41, 18]],\n",
      "\n",
      "        [[23, 40, 35,  8],\n",
      "         [32, 37, 20, 13],\n",
      "         [55, 42, 57, 21]]])\n",
      "<torch.utils.data.sampler.RandomSampler object at 0x7f714bc857d0>\n",
      "1\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = torch.randperm(60).reshape((5,3,4))\n",
    "print(a)\n",
    "b = torch.utils.data.RandomSampler(a, replacement=True, num_samples=3)\n",
    "print(b)\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SubsetRandomSampler： 从给定的索引列表中随机采样元素，不放回采样\n",
    "indices(sequence): 索引序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sunsetRandomSampler](https://img-blog.csdnimg.cn/e80f6a1bafe042f28da652dc5a2388ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[13,  8, 22, 25],\n",
      "         [37, 39,  6, 20],\n",
      "         [27, 35, 53, 26]],\n",
      "\n",
      "        [[33, 40, 19, 10],\n",
      "         [30, 17,  0, 55],\n",
      "         [18, 29,  2,  5]],\n",
      "\n",
      "        [[12, 34, 32, 16],\n",
      "         [ 9, 57, 48, 23],\n",
      "         [14,  4, 59, 41]],\n",
      "\n",
      "        [[11, 24, 28, 44],\n",
      "         [ 7, 51, 15,  1],\n",
      "         [58, 31, 21, 54]],\n",
      "\n",
      "        [[36, 52, 42, 38],\n",
      "         [45, 43, 56, 49],\n",
      "         [ 3, 46, 47, 50]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randperm(60).reshape((5,3,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 34, 32, 16],\n",
      "        [ 9, 57, 48, 23],\n",
      "        [14,  4, 59, 41]])\n",
      "tensor([[36, 52, 42, 38],\n",
      "        [45, 43, 56, 49],\n",
      "        [ 3, 46, 47, 50]])\n",
      "tensor([[11, 24, 28, 44],\n",
      "        [ 7, 51, 15,  1],\n",
      "        [58, 31, 21, 54]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.utils.data.SubsetRandomSampler(indices=a[2:])\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampler: 基采样器\n",
    "batch_size: \n",
    "drop_last=True, 如果一个batch的长度小于batch_size则丢弃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BatchSampler](https://img-blog.csdnimg.cn/8a1b2f5ae320453c9fae8ae8e0ef2080.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "a = torch.randperm(60).reshape((5,3,4))\n",
    "# print(a)\n",
    "b = torch.utils.data.BatchSampler(torch.utils.data.RandomSampler(a), 2, drop_last=True)\n",
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BucketSampler](https://img-blog.csdnimg.cn/6413cea5dfbf4494a6b2b64504f74a97.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SortedSampler](https://img-blog.csdnimg.cn/64f60217df474cf1b0d7aa1c3558cc1f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BucketSampler](https://img-blog.csdnimg.cn/d7e03938f2824f9cb8a6c3a895f5a78a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.AFQMCDataset object at 0x7f71187e93d0>\n",
      "30\n",
      "24\n",
      "25\n",
      "24\n",
      "59\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "mini_dataset = {k: v[:6] for k, v in dt['train'].items()}\n",
    "mini_data = AFQMCDataset(mini_dataset)\n",
    "print(mini_data)\n",
    "# mini_data 的前6条数据的长度\n",
    "for i, d in enumerate(mini_data):\n",
    "    print(len(d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 4, 1, 0, 2]\n",
      "[0, 5, 2, 4]\n",
      "[2, 1, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "from extra_file.bucket_sampler import SortedSampler\n",
    "random_sampler = torch.utils.data.RandomSampler(mini_data, replacement=False)\n",
    "print(list(random_sampler))\n",
    "# [3, 5, 4, 1, 0, 2]\n",
    "\n",
    "batch_sampler = torch.utils.data.BatchSampler(random_sampler, 4, drop_last=True)\n",
    "# [0, 5, 2, 4]\n",
    "\n",
    "for samp in batch_sampler:\n",
    "    print(samp)\n",
    "    sorted_sampler = SortedSampler(samp, sort_key=lambda x:len(mini_data[x][0]))\n",
    "    print(list(sorted_sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2, 1, 0, 3] \n",
    "2 -> 2 -> 25\n",
    "1 -> 5 -> 28\n",
    "0 -> 0 -> 30\n",
    "3 -> 4 -> 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [0, 3]]\n"
     ]
    }
   ],
   "source": [
    "c = list(torch.utils.data.BatchSampler(sorted_sampler, 2, drop_last=True))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从给定的索引列表中随机采样元素\n",
      "[2, 1]\n",
      "所对应的原序列是什么：\n",
      "[2, 5]\n",
      "从给定的索引列表中随机采样元素\n",
      "[0, 3]\n",
      "所对应的原序列是什么：\n",
      "[0, 4]\n"
     ]
    }
   ],
   "source": [
    "for batch in torch.utils.data.SubsetRandomSampler(c):\n",
    "    print('从给定的索引列表中随机采样元素')\n",
    "    print(batch)\n",
    "    print('所对应的原序列是什么：')\n",
    "    print([samp[i] for i in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设：batch_size = 2， 经常使用的  返回 一个batch(包含两条数据)\n",
    "桶采样： DataSet -> 搞出一个大桶（n * batch_size） -> 对于 n * 2 条数据进行排序 -> 从中抽取 batch_size（2）条（小桶）数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "现在是休息时间，看录播的同学可以跳过哦～:  10%|█         | 30/300 [00:30<04:30,  1.00s/it]"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(60*5), desc='现在是休息时间，看录播的同学可以跳过哦～'):\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "from extra_file.bucket_sampler import BucketBatchSampler\n",
    "\n",
    "def build_dataloader(config, data, collate_fn):\n",
    "    train_dataset = AFQMCDataset(data['train'])\n",
    "    dev_dataset = AFQMCDataset(data['dev'])\n",
    "    test_dataset = AFQMCDataset(data['test'])\n",
    "\n",
    "    if config['use_bucket']:\n",
    "        train_sampler = RandomSampler(train_dataset)\n",
    "        bucket_sampler = BucketBatchSampler(train_sampler, batch_size=config['batch_size'],\n",
    "                                            drop_last=False, sort_key=lambda x:len(train_dataset[x][0]),\n",
    "                                            bucket_size_multiplier=config['bucket_multiplier'])\n",
    "        train_dataloder = DataLoader(dataset=train_dataset, batch_sampler=bucket_sampler, \n",
    "                                    num_workers=4, collate_fn=collate_fn)\n",
    "    \n",
    "    else:\n",
    "        train_dataloder = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                                     shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    \n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=config['batch_size'], \n",
    "                                     shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], \n",
    "                                     shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_dataloder, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloder, dev_dataloader, test_dataloader = build_dataloader(config, dt, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2769, 4638,  ..., 5709, 1446,  102],\n",
      "        [ 101, 2769, 4638,  ..., 3119, 7178,  102],\n",
      "        [ 101, 1963,  862,  ..., 1525, 7027,  102],\n",
      "        ...,\n",
      "        [ 101, 3118,  802,  ...,  679, 6629,  102],\n",
      "        [ 101, 2972, 2408,  ...,  802, 1408,  102],\n",
      "        [ 101,  955, 1446,  ..., 6820, 3621,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloder:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动混合精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![amp](https://img-blog.csdnimg.cn/e4226734b82f462e983aa905de50891a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合精度训练\n",
    "作用：训练时，尽量不降低性能，并提升速度\n",
    "Float16优点:\n",
    "* 减少内存的使用\n",
    "* 加快训练和推断的计算，能带来多一倍速的体验\n",
    "\n",
    "Float16缺点:\n",
    "* 溢出错误\n",
    "* 舍入误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,3)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![amp2](https://img-blog.csdnimg.cn/72b642b508024cc2a6207c308347c7e7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当进入autocast()时， 系统自动切换为float16, autocast上下文只包含前向传播，建议不用反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scaling](https://img-blog.csdnimg.cn/bbae5cdd360748ecb59cee8dc6f728f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scaler.scale(loss) 将给定的损失成一缩放器的当前比例因子，进行反向传播\n",
    "* scaler.step(optimizer) 取消缩放梯度并调用optimizer.step()\n",
    "* scaler.update() 更新缩放器的比例因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GradScaler](https://img-blog.csdnimg.cn/2c0fdf08602748ea8a7655f2d5bb1829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](https://img-blog.csdnimg.cn/dfeebde4d34b496096062bb7dbbee7b6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(config, model, val_dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    val_loss = 0.\n",
    "    val_iterator = tqdm(val_dataloader, desc='Evaluation', total=len(val_dataloader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iterator:\n",
    "            labels.append(batch['labels'])\n",
    "            batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
    "            loss, logits = model(**batch_cuda)[:2]\n",
    "\n",
    "            if config['n_gpus'] > 1:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds.append(logits.argmax(dim=-1).detach().cpu())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    f1 = metrics.f1_score(labels, preds)\n",
    "    acc = metrics.accuracy_score(labels, preds)\n",
    "    return avg_val_loss, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        self.register()\n",
    "\n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对抗样本：对人类看起来一样，对模型来说预测结果却完全不一样的样本。\n",
    "\n",
    "1.相对于原始输入（词向量），所添加的扰动是微小的 2.模型犯错\n",
    "\n",
    "对抗训练：在训练集中增加一些对抗样本，希望增强模型对于对抗样本的鲁棒性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![对抗训练](https://img-blog.csdnimg.cn/20210716113626200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGM\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r\n",
    "3. 计算x+r的前向loss, 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "4. 将embedding恢复为（1）时的embedding；\n",
    "5. 根据（3）的梯度对参数进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD\n",
    "FGM是一下子算出了对抗扰动，这样得到的扰动不一定是最优的。因此PGD进行了改进，多迭代了K/t次，慢慢找到最优的扰动\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "  对于每步t：\n",
    "  2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r；\n",
    "  3. t如果不是最后一步，将梯度归0， 根据2的x+r计算前后向并得到梯度\n",
    "  4. t是最后一步，恢复1的梯度，计算最后的x+r并将梯度累加到(1)上\n",
    "5. 将embedding恢复为（1）时的embedding；\n",
    "6.根据（4）的梯度对参数进行更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.cuda import amp\n",
    "from transformers import AdamW\n",
    "from extra_file.extra_pgd import *\n",
    "from extra_file.extra_loss import *\n",
    "from extra_file.extra_fgm import *\n",
    "from extra_file.extra_optim import *\n",
    "from tqdm import trange\n",
    "def train(config, train_dataloader, dev_dataloader):\n",
    "    # 封装好 BertForSequenceClassification\n",
    "    model = BertForSequenceClassification.from_pretrained(config['model_path'])\n",
    "    \n",
    "\n",
    "    # param_optimizer = model.named_parameters()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "\n",
    "    # 实例化scaler对象 enabled=True 可以使用梯度缩放\n",
    "    scaler = amp.GradScaler(enabled=config['use_amp'])\n",
    "    \n",
    "    # 权重缩减\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    \n",
    "    # 名称包含 ['bias', 'LayerNorm.weight']的权重， 其权重衰减因子为0\n",
    "    # 名称不包含 ['bias', 'LayerNorm.weight']的权重， 其权重衰减因子为 0.01\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         \"weight_decay\": config['weight_decay']},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         \"weight_decay\": 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=config['learning_rate'], eps=1e-8)\n",
    "    \n",
    "    # lookahead 预先查看由 AdamW 生成的快速权重 来选择搜索方向\n",
    "    optimizer = Lookahead(optimizer, 5, 1)\n",
    "    total_steps = config['num_epochs'] * len(train_dataloader)\n",
    "\n",
    "    # 使用Warmup来调整学习率，每调用warmup_steps次，对应的学习率就会调整一次。\n",
    "    lr_scheduler = WarmupLinearSchedule(optimizer,\n",
    "                                        warmup_steps=int(config['warmup_ratio'] * total_steps),\n",
    "                                        t_total=total_steps)\n",
    "    model.to(config['device'])\n",
    "\n",
    "    if config['adv'] == 'fgm':\n",
    "        fgm = FGM(model)\n",
    "    else:\n",
    "        pgd = PGD(model)\n",
    "        K = 3\n",
    "    \n",
    "    epoch_iterator = trange(config['num_epochs'])\n",
    "    global_steps = 0\n",
    "    train_loss = 0.\n",
    "    logging_loss = 0.\n",
    "    best_acc = 0.\n",
    "    best_model_path = ''\n",
    "    \n",
    "    # 多卡 情况\n",
    "    if config['n_gpus'] > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "\n",
    "        train_iterator = tqdm(train_dataloader, desc='Training', total=len(train_dataloader))\n",
    "        model.train()\n",
    "        for batch in train_iterator:\n",
    "            batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
    "            \n",
    "            # 前向过程（前向传播 + loss）\n",
    "            with amp.autocast(enabled=config['use_amp']):\n",
    "                loss = model(**batch_cuda)[0]\n",
    "                # 多卡 取平均\n",
    "                if config['n_gpus'] > 1:\n",
    "                    loss = loss.mean()\n",
    "            \n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if config['adv'] == 'fgm':\n",
    "                # 在embedding上加扰动\n",
    "                fgm.attack(epsilon=config['eps'])\n",
    "                \n",
    "                # autocast\n",
    "                with amp.autocast(enabled=config['use_amp']):\n",
    "                    loss_adv = model(**batch_cuda)[0]\n",
    "                   \n",
    "                    if config['n_gpus'] > 1:\n",
    "                        loss_adv = loss_adv.mean()\n",
    "                \n",
    "                scaler.scale(loss_adv).backward()\n",
    "                # 恢复embedding参数\n",
    "                fgm.restore()\n",
    "            else:\n",
    "                pgd.backup_grad()\n",
    "                for t in range(K):\n",
    "                    pgd.attack(epsilon=config['eps'], alpha=config['alpha'], is_first_attack=(t == 0))\n",
    "                    if t != K - 1:\n",
    "                        model.zero_grad()\n",
    "                    else:\n",
    "                        pgd.restore_grad()\n",
    "                    with amp.autocast(enabled=config['use_amp']):\n",
    "                        loss_adv = model(**batch_cuda)[0]\n",
    "                        if config['n_gpus'] > 1:\n",
    "                            loss_adv = loss_adv.mean()\n",
    "\n",
    "                    scaler.scale(loss_adv).backward()\n",
    "                pgd.restore()\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if config['ema_start']:\n",
    "                ema.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            global_steps += 1\n",
    "\n",
    "            train_iterator.set_postfix_str(f'running training loss: {loss.item():.4f}')\n",
    "\n",
    "            if global_steps % config['logging_step'] == 0:\n",
    "                if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
    "                    print('\\n>>> EMA starting ...')\n",
    "                    config['ema_start'] = True\n",
    "                    \n",
    "                    ema = EMA(model.module if hasattr(model, 'module') else model, decay=0.999)\n",
    "\n",
    "                print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
    "                logging_loss = train_loss\n",
    "\n",
    "\n",
    "                if config['ema_start']:\n",
    "                    ema.apply_shadow()\n",
    "                val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
    "\n",
    "                print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f}, '\n",
    "\n",
    "                if acc > best_acc:\n",
    "                    model_save_path = os.path.join(config['output_path'],\n",
    "                                                   f'checkpoint-{global_steps}-{acc:.6f}')\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "                    model_to_save.save_pretrained(model_save_path)\n",
    "                    best_acc = acc\n",
    "                    best_model_path = model_save_path\n",
    "\n",
    "                print_log += f'valid f1: {f1:.6f}, valid acc: {acc:.6f}'\n",
    "\n",
    "                print(print_log)\n",
    "                model.train()\n",
    "\n",
    "                if config['ema_start']:\n",
    "                    ema.restore()\n",
    "\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at data/data94445 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at data/data94445 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py:111: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/537 [00:00<?, ?it/s]\u001b[A/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py:114: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "Training:   0%|          | 0/537 [00:07<?, ?it/s]\n",
      "  0%|          | 0/1 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5c5265c79542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-c19731542027>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, train_dataloader, dev_dataloader)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mpgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \"\"\"\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"closure\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/extra_file/extra_optim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"counter\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;31m# Exponential moving average of gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exp_avg\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m                     \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exp_avg_sq\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config, train_dataloder, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
