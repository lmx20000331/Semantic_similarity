{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Tensor](https://img-blog.csdnimg.cn/73d79be2ccaa413fa252072169e38573.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor(4)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "np_array = np.array(data)\n",
    "x_tensor = torch.from_numpy(np_array)\n",
    "print(x_tensor)\n",
    "one_element = x_tensor[1][1]\n",
    "print(one_element)\n",
    "print(one_element.item())  # 只有一个元素的tensor才能使用item函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.5309, 0.5070],\n",
      "        [0.5631, 0.9979]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "# 修改新张量的数据类型\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 改变张量 tensor 的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![reshape](https://img-blog.csdnimg.cn/a06143c7aaa54007a75c4b5bd2ecac1b.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2097, -0.2918,  2.8595, -0.0547],\n",
      "        [ 0.1935,  1.2770,  0.5390, -2.3792],\n",
      "        [ 0.7055,  0.1889, -0.0337, -0.0768],\n",
      "        [-0.3051, -0.7940,  0.4360,  2.5206]])\n",
      "torch.Size([4, 4])\n",
      "tensor([[ 1.2097, -0.2918,  2.8595, -0.0547,  0.1935,  1.2770,  0.5390, -2.3792],\n",
      "        [ 0.7055,  0.1889, -0.0337, -0.0768, -0.3051, -0.7940,  0.4360,  2.5206]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "print(x.size())\n",
    "y = torch.reshape(x, (2, 8))\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![view](https://img-blog.csdnimg.cn/ba63b09a4ef845b287ae01a45c0ef2c7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2097, -0.2918,  2.8595, -0.0547,  0.1935,  1.2770,  0.5390, -2.3792,\n",
      "         0.7055,  0.1889, -0.0337, -0.0768, -0.3051, -0.7940,  0.4360,  2.5206])\n",
      "torch.Size([16])\n",
      "tensor([[ 0.0000, -0.2918,  2.8595, -0.0547],\n",
      "        [ 0.1935,  1.2770,  0.5390, -2.3792],\n",
      "        [ 0.7055,  0.1889, -0.0337, -0.0768],\n",
      "        [-0.3051, -0.7940,  0.4360,  2.5206]])\n",
      "tensor([ 0.0000, -0.2918,  2.8595, -0.0547,  0.1935,  1.2770,  0.5390, -2.3792,\n",
      "         0.7055,  0.1889, -0.0337, -0.0768, -0.3051, -0.7940,  0.4360,  2.5206])\n"
     ]
    }
   ],
   "source": [
    "# view 返回的原数据的引用\n",
    "# 有时候 tensor 不连续，就没法使用 view， 可以使用 reshape. 如果一定要使用 view, 则先调用 contuiguous(), 在view。\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "print(y.size())\n",
    "x[0][0] = 0\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[1],\n",
      "        [2]])\n",
      "tensor([[1, 2, 3],\n",
      "        [5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2,3)\n",
    "print(a)\n",
    "b = torch.arange(1, 3).reshape(2,1)\n",
    "print(b)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n",
      "tensor([[1, 3, 5],\n",
      "        [4, 6, 8]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.arange(1,4).reshape(1,3)\n",
    "print(c) # [[1,2,3],[1,2,3]]\n",
    "print(a+c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## squeeze "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![squeeze](https://img-blog.csdnimg.cn/8845529d07984e2c82a3ee2845e70eb4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2, 1, 2])\n",
      "torch.Size([2, 1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,1,2,1,2)\n",
    "print(x.size())\n",
    "y = torch.squeeze(x)    # 删除了大小为1的所有维度\n",
    "# squeeze来减少tensor的维度\n",
    "print(y.size())\n",
    "\n",
    "y = torch.squeeze(x, 1)\n",
    "print(y.size())   # 删除 dim=1 的维度\n",
    "\n",
    "y = torch.squeeze(x, 0)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![unsqueeze](https://img-blog.csdnimg.cn/91694a970afb42ee91e0933fba4388d4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4])\n",
    "print(x.size())\n",
    "y = torch.unsqueeze(x, 0)\n",
    "print(y.size())\n",
    "y = torch.unsqueeze(x, 1)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 交换维度/改变维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n",
      "torch.Size([4, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "# transpose 转置 一次只能改变2个维度的位置\n",
    "x = torch.ones(3,4,5)\n",
    "print(x.size())\n",
    "y = x.transpose(0,1)\n",
    "print(y.size())\n",
    "\n",
    "# permute 可以同时改变多个维度的位置\n",
    "y = x.permute(1,2,0)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 组合（stack/cat）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![stack](https://img-blog.csdnimg.cn/474af12235964ae7a44840bbec13d98a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1514, 0.5191, 0.6667, 0.3323],\n",
      "        [0.7784, 0.7498, 0.0861, 0.4328],\n",
      "        [0.6962, 0.1142, 0.0742, 0.3999]])\n",
      "tensor([[0.0594, 0.9961, 0.3403, 0.3854],\n",
      "        [0.1247, 0.3389, 0.2981, 0.7379],\n",
      "        [0.4233, 0.6466, 0.5118, 0.1789]])\n",
      "tensor([[[0.1514, 0.5191, 0.6667, 0.3323],\n",
      "         [0.0594, 0.9961, 0.3403, 0.3854]],\n",
      "\n",
      "        [[0.7784, 0.7498, 0.0861, 0.4328],\n",
      "         [0.1247, 0.3389, 0.2981, 0.7379]],\n",
      "\n",
      "        [[0.6962, 0.1142, 0.0742, 0.3999],\n",
      "         [0.4233, 0.6466, 0.5118, 0.1789]]])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# stack 在新维度进行拼接\n",
    "a = torch.rand(3,4)\n",
    "print(a)\n",
    "b = torch.rand(3,4)\n",
    "print(b)\n",
    "c = torch.stack([a,b], 1)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "# (3, 4) -> (3, 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![cat](https://img-blog.csdnimg.cn/0bfa66a00a7045019be1f70b75f73516.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1514, 0.5191, 0.6667, 0.3323],\n",
      "        [0.7784, 0.7498, 0.0861, 0.4328],\n",
      "        [0.6962, 0.1142, 0.0742, 0.3999],\n",
      "        [0.0594, 0.9961, 0.3403, 0.3854],\n",
      "        [0.1247, 0.3389, 0.2981, 0.7379],\n",
      "        [0.4233, 0.6466, 0.5118, 0.1789]])\n",
      "torch.Size([6, 4])\n",
      "tensor([[0.1514, 0.5191, 0.6667, 0.3323, 0.0594, 0.9961, 0.3403, 0.3854],\n",
      "        [0.7784, 0.7498, 0.0861, 0.4328, 0.1247, 0.3389, 0.2981, 0.7379],\n",
      "        [0.6962, 0.1142, 0.0742, 0.3999, 0.4233, 0.6466, 0.5118, 0.1789]])\n",
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# cat 在现有维度上进行拼接\n",
    "c = torch.cat([a,b], 0)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "c = torch.cat([a,b], 1)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## gather 按维度索引取值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![torch.gather](https://img-blog.csdnimg.cn/25de3a36cfec457f835bff4258bd78bc.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1, 1],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "print(t.shape)\n",
    "y = torch.gather(t, 1,torch.tensor([[0,0],[1,0]]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![gather](https://img-blog.csdnimg.cn/28fb4f245c66462fb9a5918b02154812.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 2]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.gather(t, 0, torch.tensor([[0,0],[1,0]]))\n",
    "print(y)  #[[1,2],[3,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "提出：深度学习需要通过大量数据避免过拟合。\n",
    "数据增强：通过有限的数据产生更多的等价数据来人工扩展训练数据集的技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## EDA（Easy Data Augmentation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![EDA3](https://img-blog.csdnimg.cn/50c22b4212714b509ce053ff921d6bdd.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
    "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
    "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
    "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
    "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 闭包数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据集中每条数据有两条句子, 现在共3条句子\\\n",
    "a, b, 1\\\n",
    "a, c, 1\\\n",
    "a, d, 0\\\n",
    "a~b, a~c => b~c\\\n",
    "a~b, a 和 d 不相似 => ad不相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对偶数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### a-b对，变成b-a对, 把两个句子换顺序\n",
    "### 我们的无监督数据增强就是用的对偶数据增强\n",
    "### BERT 输入 a，b两个句子，现在输入以b,a作为输入，增强样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### UDA（Unsupervised Data Augmentation for Consistency Training）用于一致性训练的无监督数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![UDA5](https://img-blog.csdnimg.cn/9d10da70d1d0467e93ef5bb1267ac87f.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![code](https://img-blog.csdnimg.cn/d97f35fd41e0485185f40d50f4fd8e8d.png?x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TextCNN 源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "config = {\n",
    "    'train_file_path': 'data/data86671/train.csv',\n",
    "    'test_file_path': 'data/data86671/test.csv',\n",
    "    'train_val_ratio': 0.1,  # 10%用作验证集\n",
    "    'vocab_size': 30000,   # 词典 3W\n",
    "    'batch_size': 64,      # batch 大小 64\n",
    "    'num_epochs': 2,      # 2次迭代\n",
    "    'learning_rate': 1e-3, # 学习率\n",
    "    'logging_step': 300,   # 每跑300个batch记录一次\n",
    "    'seed': 2021           # 随机种子\n",
    "}\n",
    "\n",
    "config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' # cpu&gpu\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train.csv 四列 id, label, label_desc, sentence\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "def get_vocab(config):\n",
    "    token_counter = Counter()\n",
    "    with open(config['train_file_path'], 'r', encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines, desc='Counting tokens', total=len(lines)):\n",
    "            sent = line.split(',')[-1].strip()\n",
    "            sent_cut = list(jieba.cut(sent))\n",
    "            token_counter.update(sent_cut)\n",
    "            # token_counter {'我': 2,'是': 5}\n",
    "    \n",
    "    vocab = set(token for token, _ in token_counter.most_common(config['vocab_size']))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting tokens:   0%|          | 0/53361 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.822 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Counting tokens: 100%|██████████| 53361/53361 [00:07<00:00, 7465.68it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将 词典（vocab） 中的token 转化为 词向量\n",
    "# token -> embedding \n",
    "# token -> id\n",
    "\n",
    "# '是' <-> 10 <-> 300d Vector\n",
    "\n",
    "def get_embedding(vocab):\n",
    "    token2embedding ={}\n",
    "\n",
    "    with bz2.open('data/data86671/sgns.weibo.word.bz2') as f:\n",
    "        token_vector = f.readlines()\n",
    "\n",
    "        meta_info = token_vector[0].split()\n",
    "        print(f'{meta_info[0]} tokens in embedding file in total, vector size is {meta_info[1]}')\n",
    "\n",
    "        # sgns.weibo.word.bz2 从第二行开始，每一行是 'token embedding' 的形式\n",
    "        # '我' 0.88383 0.22222 *300\n",
    "        for line in tqdm(token_vector[1:]):\n",
    "            line = line.split()\n",
    "            token = line[0].decode('utf8')\n",
    "\n",
    "            vector = line[1:]\n",
    "\n",
    "            if token in vocab:\n",
    "                token2embedding[token] = [float(num) for num in vector]\n",
    "\n",
    "        # enumerate(, [start])\n",
    "        token2id = {token: idx for idx, token in enumerate(token2embedding.keys(), 4)}\n",
    "        id2embedding = {token2id[token]: embedding for token, embedding in token2embedding.items()}\n",
    "\n",
    "        PAD, UNK, BOS, EOS = '<pad>', '<unk>', '<bos>', '<eos>'\n",
    "\n",
    "        token2id[PAD] = 0\n",
    "        token2id[UNK] = 1\n",
    "        token2id[BOS] = 2\n",
    "        token2id[EOS] = 3\n",
    "\n",
    "        id2embedding[0] = [.0] * int(meta_info[1])\n",
    "        id2embedding[1] = [.0] * int(meta_info[1])\n",
    "\n",
    "        id2embedding[2] = np.random.random(int(meta_info[1])).tolist()\n",
    "        id2embedding[3] = np.random.random(int(meta_info[1])).tolist()\n",
    "\n",
    "        emb_mat = [id2embedding[idx] for idx in range(len(id2embedding))]\n",
    "\n",
    "        return torch.tensor(emb_mat, dtype=torch.float), token2id, len(vocab)+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 776/195202 [00:00<00:25, 7758.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'195202' tokens in embedding file in total, vector size is b'300'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3600/195202 [00:00<00:18, 10089.08it/s]100%|██████████| 195202/195202 [00:04<00:00, 45270.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "emb_mat, token2id, config['vocab_size'] = get_embedding(vocab)\n",
    "# print(token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenizer(sent, token2id):\n",
    "    ids = [token2id.get(token, 1) for token in jieba.cut(sent)]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "def read_data(config, token2id, mode='train'):\n",
    "    data_df = pd.read_csv(config[f'{mode}_file_path'], sep=',')\n",
    "    if mode == 'train':\n",
    "        X_train, y_train = defaultdict(list), []\n",
    "        X_val, y_val = defaultdict(list), []\n",
    "        num_val = int(config['train_val_ratio'] * len(data_df))\n",
    "    \n",
    "    else:\n",
    "        X_test, y_test = defaultdict(list), []\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), desc=f'Preprocesing {mode} data', total=len(data_df)):\n",
    "        label=row[1] if mode == 'train' else 0\n",
    "        sentence = row[-1]\n",
    "        inputs = tokenizer(sentence, token2id)\n",
    "        if mode == 'train':\n",
    "            if i < num_val:\n",
    "                X_val['input_ids'].append(inputs)\n",
    "                y_val.append(label)\n",
    "            else:\n",
    "                X_train['input_ids'].append(inputs)\n",
    "                y_train.append(label)\n",
    "        \n",
    "        else:\n",
    "            X_test['input_ids'].append(inputs)\n",
    "            y_test.append(label)\n",
    "\n",
    "    if mode == 'train':\n",
    "        label2id = {label: i for i, label in enumerate(np.unique(y_train))}\n",
    "        id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "        y_train = torch.tensor([label2id[label] for label in y_train], dtype=torch.long)\n",
    "        y_val = torch.tensor([label2id[label] for label in y_val], dtype=torch.long)\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, label2id, id2label\n",
    "    \n",
    "    else:\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocesing train data: 100%|██████████| 53360/53360 [00:12<00:00, 4253.68it/s]\n",
      "Preprocesing test data: 100%|██████████| 10000/10000 [00:02<00:00, 4188.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, label2id, id2label = read_data(config, token2id, mode='train')\n",
    "X_test, y_test = read_data(config, token2id, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataset、DataLoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[torch.utils.data.DataLoader](https://zhuanlan.zhihu.com/p/402666821)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![dataset&dataloaders](https://img-blog.csdnimg.cn/c4ba8de5a4934a68a071c0b03f16d8cf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "from torch.utils.data import Dataset   # All datasets that represent a map from keys to data samples should subclass it. \n",
    "class TNEWSDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])   # supporting fetching a data sample for a given key. \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TNEWSDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.x['input_ids'][idx],\n",
    "            'label': self.y[idx]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = TNEWSDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2258, 2362, 10, 199, 2362, 18, 5984, 17686, 1237, 4280, 19, 1, 23], 'label': tensor(7)}\n",
      "48024\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[100]) # 返回某条sample \n",
    "print(len(train_dataset)) # 返回整个数据集的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collete_fn(examples):\n",
    "    input_ids_list =[]\n",
    "    labels = []\n",
    "    for example in examples:\n",
    "        input_ids_list.append(example['input_ids'])\n",
    "        labels.append(example['label'])\n",
    "    \n",
    "    # 1.找到 input_ids_list 中最长的句子\n",
    "    max_length = max(len(input_ids) for input_ids in input_ids_list)\n",
    "\n",
    "    # 2. 定义一个Tensor\n",
    "    input_ids_tensor = torch.zeros((len(labels), max_length), dtype=torch.long)\n",
    "\n",
    "    for i, input_ids in enumerate(input_ids_list):\n",
    "        # 3.得到当前句子长度\n",
    "        seq_len = len(input_ids)\n",
    "        input_ids_tensor[i, :seq_len] = torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids_tensor,\n",
    "        'label': torch.tensor(labels, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "def collate_fn(examples):    \n",
    "    input_ids_list = []\n",
    "    labels = []\n",
    "\n",
    "    for example in examples:\n",
    "        input_ids_list.append(example[0])\n",
    "        labels.append(example[1])\n",
    "\n",
    "    max_length = max(len(input_ids) for input_ids in input_ids_list)\n",
    "\n",
    "    input_ids_tensor = torch.zeros((len(labels), max_length), dtype=torch.long)\n",
    "    for i, input_ids in enumerate(input_ids_list):\n",
    "        seq_len = len(input_ids)\n",
    "        input_ids_tensor[i, :seq_len] = torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return (input_ids_tensor, label_tensor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "class Collator:\n",
    "    def __init__(self, max_seq_len):\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_max_seq_len(self, ids_list):\n",
    "        cur_max_seq_len = max(len(input_id) for input_id in ids_list)\n",
    "        max_seq_len = min(self.max_seq_len, cur_max_seq_len)\n",
    "        return max_seq_len\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_and_truncate(text_ids_list, max_seq_len):\n",
    "        input_ids = torch.zeros((len(text_ids_list), max_seq_len), dtype=torch.long)\n",
    "        for i, text_ids in enumerate(text_ids_list):\n",
    "            seq_len = min(len(text_ids), max_seq_len)\n",
    "            input_ids[i, :seq_len] = torch.tensor(text_ids[:seq_len], dtype=torch.long)\n",
    "        \n",
    "        return input_ids\n",
    "\n",
    "    \n",
    "    def __call__(self, examples):\n",
    "        # 1. 将元组中属于sentence1的放在一起，属于sentence2的放在一起，属于label的放在一起\n",
    "        text_ids_left_list, text_ids_right_list, labels_list = list(zip(*examples))\n",
    "\n",
    "        # 2.1 找到 text_ids_left_list, text_ids_right_list 最长的句子长度\n",
    "        max_text_left_length = self.get_max_seq_len(text_ids_left_list)\n",
    "        max_text_right_length = self.get_max_seq_len(text_ids_right_list)\n",
    "\n",
    "        # 2.2 执行短暂句子补齐, 3.定义一个tensor，把数据放里面\n",
    "        text_left_ids = self.pad_and_truncate(text_ids_left_list, max_text_left_length)\n",
    "        text_right_ids = self.pad_and_truncate(text_ids_right_list, max_text_right_length)\n",
    "        labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "        \n",
    "        data_list = [text_left_ids, text_right_ids, labels]\n",
    "        return data_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def build_dataloader(config, vocab):\n",
    "    X_train, y_train, X_val, y_val, label2id, id2label = read_data(config, token2id, mode='train')\n",
    "    X_test, y_test = read_data(config, token2id, mode='test')\n",
    "\n",
    "    train_dataset = TNEWSDataset(X_train, y_train)\n",
    "    val_dataset = TNEWSDataset(X_val, y_val)\n",
    "    test_dataset = TNEWSDataset(X_test, y_test)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], num_workers=4, shuffle=True, collate_fn=collete_fn)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'], num_workers=4, shuffle=False, collate_fn=collete_fn)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config['batch_size'], num_workers=4, shuffle=False, collate_fn=collete_fn)\n",
    "\n",
    "    return id2label, train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "from torch.utils.data import DataLoader\n",
    "def build_dataloader(train_df, test_df, config, vocab):\n",
    "    X_train, y_train, X_val, y_val, label2id, id2label = read_data(train_df, config['train_val_ratio'], vocab, mode='train')\n",
    "    X_test, y_test = read_data(test_df, config['train_val_ratio'], vocab, mode='test')\n",
    "\n",
    "    train_dataset = AFQMCDataset(X_train, y_train)\n",
    "    val_dataset = AFQMCDataset(X_val, y_val)\n",
    "    test_dataset = AFQMCDataset(X_test, y_test)\n",
    "    \n",
    "    # -----------------new -----------------------#\n",
    "    collate_fn = Collator(config['max_seq_len'])\n",
    "    # -----------------new -----------------------#\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'],\n",
    "                                  num_workers=4, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'],\n",
    "                                num_workers=4, shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config['batch_size'],\n",
    "                                 num_workers=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return id2label, test_dataloader, train_dataloader, val_dataloader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocesing train data: 100%|██████████| 53360/53360 [00:12<00:00, 4318.02it/s]\n",
      "Preprocesing test data: 100%|██████████| 10000/10000 [00:02<00:00, 4408.49it/s]\n"
     ]
    }
   ],
   "source": [
    " id2label, train_dataloader, val_dataloader, test_dataloader = build_dataloader(config, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 打印 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 1793, 20039,  1034,  ...,     0,     0,     0],\n",
      "        [  348,  2484, 10497,  ...,     0,     0,     0],\n",
      "        [ 7051, 13667,  6551,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  170, 17538,  8992,  ...,     0,     0,     0],\n",
      "        [    1, 10274,     1,  ...,     0,     0,     0],\n",
      "        [  290,     1,     9,  ...,     0,     0,     0]]), 'label': tensor([ 7,  3,  3,  6,  3,  9, 13, 10,  9,  2, 10,  8,  8,  8,  9, 14,  3,  3,\n",
      "        14,  5,  6, 14,  1,  9,  8, 10,  8,  6,  1,  2,  6, 10,  9,  3,  8,  3,\n",
      "         6,  8, 11,  4, 11,  5,  8,  1, 14,  9,  3, 11,  2, 11,  4,  0,  1,  3,\n",
      "         8,  8,  5,  2, 12,  5, 13, 11,  9,  6])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 所有采样器都继承自Sampler这个类\n",
    "## 每个Sampler子类都要实现__iter__方法【迭代数据集example索引的方法】，以及返回迭代器长度的__len__方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SequentialSampler: 在初始化时拿到数据集， 按顺序对元素进行采样，每次返回一个索引值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RandomSampler：随机采样（可以重复采样）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SubsetRandomSampler： 从给定的索引列表中随机采样元素，不放回采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BatchSampler（Sampler）: 之前的采样器每次只返回一个索引值，将基采样器采样的到的索引值进行合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![BucketSampler](https://img-blog.csdnimg.cn/d7e03938f2824f9cb8a6c3a895f5a78a.png?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "现在是休息时间，看录播的同学可以跳过哦！～: 100%|██████████| 900/900 [15:02<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(60*15), desc=\"现在是休息时间，看录播的同学可以跳过哦！～\"):\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n",
    "for batch in train_iterator:\n",
    "    loss = model(**batch)[0] # 正向传播\n",
    "    model.zero_grad()    # 梯度清0\n",
    "    loss.backward()      # 反向传播\n",
    "    optimizer.step()     # 更新网络的权重\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TextCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![TextCNN图](https://img-blog.csdnimg.cn/2021063014002246.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(config['embedding_pretrained'], freeze=True)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, config['num_filters'], (k, config['emb_size'])) for k in config['filter_sizes']])\n",
    "\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "\n",
    "        # 变换维度，得到logits\n",
    "        self.fc = nn.Linear(len(config['filter_sizes'] * config['num_filters']), config['num_classes'])\n",
    "\n",
    "    def convs_and_pool(self, x, conv):\n",
    "\n",
    "        # x [batch_size, out_channels, seq_len_out, 1]\n",
    "        # x [batch_size, out_channels, seq_len_out]\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "\n",
    "        # x (batch_size, out_channels, 1)\n",
    "        # x (batch_size, out_channels)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input_ids=None, label=None):\n",
    "        # out [batch_size, seq_len, embedding_dim]\n",
    "        out = self.embedding(input_ids)\n",
    "        \n",
    "        # H: seq_len; W:embedding_dim\n",
    "        # out [batch_size, 1, seq_len, embedding_dim]\n",
    "        out = out.unsqueeze(1)\n",
    "\n",
    "        # (batch_size, out_channels)\n",
    "        out = torch.cat([self.convs_and_pool(out, conv) for conv in self.convs], 1)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        output = (out, )\n",
    "\n",
    "        if label is not None: # 训练集用\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(out, label)\n",
    "            output = (loss, ) + output\n",
    "\n",
    "        # train output (loss, out)\n",
    "        # test output (out)\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ESIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![ESIM](https://img-blog.csdnimg.cn/img_convert/1adb67ec46e87da23fa042f298ff88bb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![all of gongshi](https://img-blog.csdnimg.cn/652165f9f0584ac683c0df8d412514be.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![stackRNN](https://img-blog.csdnimg.cn/02b1b24b629c4defabb888776f9d3f57.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "import torch.nn.functional as F\n",
    "class StackedBRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,\n",
    "                 dropout_rate=0, dropout_output=False, rnn_type=nn.LSTM, \n",
    "                 concat_layers=False):\n",
    "        super().__init__()\n",
    "        self.dropout_output = dropout_output\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.concat_layers = concat_layers\n",
    "        self.rnns = nn.ModuleList()\n",
    "        # 共有两层LSTM\n",
    "        for i in range(num_layers):\n",
    "            input_size = input_size if i == 0 else 2*hidden_size\n",
    "            self.rnns.append(rnn_type(input_size, hidden_size, num_layers=1, bidirectional=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x (B, L, D) -> (L, B, D)\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "\n",
    "            if self.dropout_rate > 0:\n",
    "                rnn_input = F.dropout(rnn_input, p=self.dropout_rate, training=self.training)\n",
    "            \n",
    "            # self.rnn[i](rnn_input) (output, (h_n, c_n))\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "        \n",
    "        # outputs [x, output0, output1]\n",
    "        if self.concat_layers:\n",
    "            output = torch.cat(outputs[1:], 2)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "        \n",
    "        # output (L, B, D) -> (B, L, D)\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        if self.dropout_output and self.dropout_rate > 0:\n",
    "            output = F.dropout(output, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        # 进行 transpose之后，tensor在内存中不连续， contiguous将output内存连续\n",
    "        return output.contiguous()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "import torch.nn as nn\n",
    "class RNNDropout(nn.Dropout):\n",
    "    # 将词向量 某些维度 清0\n",
    "    # sequences_batch [B, L, D]\n",
    "    def forward(self, sequences_batch):\n",
    "        # ones [B, D]\n",
    "        ones = sequences_batch.data.new_ones(sequences_batch.shape[0], sequences_batch.shape[-1])\n",
    "\n",
    "        # 随机 mask ones\n",
    "        # dropout_mask [B, D]\n",
    "        dropout_mask = nn.functional.dropout(ones, self.p, self.training, inplace=False)\n",
    "       \n",
    "        return dropout_mask.unsqueeze(1) * sequences_batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "class BidirectionalAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # v1 [B, L, H]\n",
    "        # v1_mask [B, L]\n",
    "        # v2 [B, R, H]\n",
    "        # v2_mask [B, R]\n",
    "    def forward(self, v1, v1_mask, v2, v2_mask):\n",
    "        # v2:a v1:b \n",
    "\n",
    "        # 1.计算矩阵相似度\n",
    "        # similarity_matrix [B, L, R]\n",
    "        similarity_matrix = v1.bmm(v2.transpose(2, 1).contiguous())\n",
    "\n",
    "        # 2.计算attention时没有必要计算pad=0, 要进行mask操作 3.进行softmax\n",
    "        # 将similarity_matrix v1中pad对应的权重给mask\n",
    "        # [B, L, R]\n",
    "        v2_v1_attn = F.softmax(\n",
    "            similarity_matrix.masked_fill(\n",
    "                v1_mask.unsqueeze(2), -1e7), dim=1)\n",
    "\n",
    "        # 将similarity_matrix v2中pad对应的权重给mask\n",
    "        # [B, L, R]\n",
    "        v1_v2_attn = F.softmax(\n",
    "            similarity_matrix.masked_fill(\n",
    "                v2_mask.unsqueeze(1), -1e7),dim=2)\n",
    "\n",
    "        # 4.计算attention\n",
    "        # [B, L, R] @ [B, R, H] \n",
    "        # 句子a 对b的影响 [B, L, H]\n",
    "        # attented_v1 [B, L, H]\n",
    "        attented_v1 = v1_v2_attn.bmm(v2)\n",
    "\n",
    "        # 句子b 对a的影响 \n",
    "        # v2_v1_attn [B, L, R] -> [B, R, L] @[B, L, H] -> [B, R, H]\n",
    "        # attented_v2 [B, R, H]\n",
    "        attented_v2 = v2_v1_attn.transpose(1,2).bmm(v1)\n",
    "\n",
    "        # attented_v1 将v1对应的pad填充为0\n",
    "        # attented_v2 将v2对应的pad填充为0\n",
    "        attented_v1.masked_fill(v1_mask.unsqueeze(2), 0)\n",
    "        attented_v2.masked_fill(v2_mask.unsqueeze(2), 0)\n",
    "        return attented_v1, attented_v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "class ESIM(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # -----------------------   input encoding  ---------------------#\n",
    "        rnn_mapping = {'lstm': nn.LSTM, 'gru': nn.GRU}\n",
    "        self.embedding = nn.Embedding.from_pretrained(config['embedding'], freeze=config['freeze_emb'])\n",
    "\n",
    "        self.rnn_dropout = RNNDropout(p=config['dropout'])\n",
    "        rnn_size = config['hidden_size']\n",
    "\n",
    "        if config['concat_layers']:\n",
    "            rnn_size //= config['num_layers']\n",
    "\n",
    "        self.input_encoding = StackedBRNN(input_size=config['embedding'].size(1),\n",
    "                                          hidden_size=rnn_size // 2,\n",
    "                                          num_layers=config['num_layers'],\n",
    "                                          rnn_type=rnn_mapping[config['rnn_type']],\n",
    "                                          concat_layers=config['concat_layers'])\n",
    "\n",
    "        # -----------------------   input encoding  ---------------------#\n",
    "\n",
    "        # -----------------------   Local inference collected over sequences  ---------------------#\n",
    "        self.attention = BidirectionalAttention()\n",
    "        # -----------------------   Local inference collected over sequences  ---------------------#\n",
    "\n",
    "\n",
    "        # -----------------------   the compositon layer  ---------------------#\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(4 * config['hidden_size'], config['hidden_size']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        self.composition = StackedBRNN(input_size=config['hidden_size'],\n",
    "                                      hidden_size=rnn_size // 2,\n",
    "                                      num_layers=config['num_layers'],\n",
    "                                      rnn_type=rnn_mapping[config['rnn_type']],\n",
    "                                      concat_layers=config['concat_layers'])\n",
    "\n",
    "\n",
    "        # -----------------------   the compositon layer  ---------------------#\n",
    "\n",
    "\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Dropout(p=config['dropout']),\n",
    "            nn.Linear(4 * config['hidden_size'], config['hidden_size']),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=config['dropout']))\n",
    "            \n",
    "        self.out = nn.Linear(config['hidden_size'], config['num_labels'])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: [sentence1_tensor, sentence2_tensor, labels_tensor]\n",
    "        # B: batch_size\n",
    "        # L = 'inputs left'  sequence length\n",
    "        # R = 'inputs right'  sequence length\n",
    "        # D = embedding size\n",
    "        # H = hidden size\n",
    "\n",
    "        # -----------------------   input encoding  ---------------------#\n",
    "        # query sentence1_tensor\n",
    "        # doc sentence2_tensor\n",
    "   \n",
    "        # query [B, L]\n",
    "        # doc [B, R] \n",
    "        query, doc = inputs[0].long(), inputs[1].long()\n",
    "        \n",
    "        # 判断 query，doc中的每一个数是不是0， 是1则表示该位置是pad\n",
    "        # query：[2,3,4,5,0,0,0] -> query_mask：[0,0,0,0,1,1,1]\n",
    "        # query_mask [B, L]\n",
    "        # doc_mask [B, R]\n",
    "        query_mask = (query == 0)\n",
    "        doc_mask = (doc == 0)\n",
    "        \n",
    "        # query [B, L, D]\n",
    "        # doc [B, R, D]\n",
    "        query = self.embedding(query)\n",
    "        doc = self.embedding(doc)\n",
    "        \n",
    "        # query [B, L, D]\n",
    "        # doc [B, R, D]\n",
    "        query = self.rnn_dropout(query)\n",
    "        doc = self.rnn_dropout(doc)\n",
    "        \n",
    "        # query [B, L, H]\n",
    "        # doc [B, R, H]\n",
    "        query = self.input_encoding(query)\n",
    "        doc = self.input_encoding(doc)\n",
    "        # -----------------------   input encoding  ---------------------#\n",
    "\n",
    "        # 1.计算矩阵相似度\n",
    "        # 2.计算attention时没有必要计算pad=0, 要进行mask操作\n",
    "        # 3.进行softmax\n",
    "        # 4.计算attention\n",
    "\n",
    "        # -----------------------   Local inference collected over sequences  ---------------------#\n",
    "        # query [B, L, H]\n",
    "        # query_mask [B, L]\n",
    "        # doc [B, R, H]\n",
    "        # doc_mask [B, R]\n",
    "        attended_query, attended_doc = self.attention(query, query_mask, doc, doc_mask)\n",
    "        # -----------------------   Local inference collected over sequences  ---------------------#\n",
    "\n",
    "        # -----------------------  Enhancement of local inference information ---------------------#\n",
    "        # enhanced_query [B, L, 4*h]\n",
    "        # enhanced_doc [B, R, 4*h]\n",
    "        enhanced_query = torch.cat([query, \n",
    "                                    attended_query, \n",
    "                                    query-attended_query, \n",
    "                                    query*attended_query], \n",
    "                                    dim=-1)\n",
    "        \n",
    "        enhanced_doc = torch.cat([doc, \n",
    "                                  attended_doc, \n",
    "                                  doc-attended_doc, \n",
    "                                  doc*attended_doc], \n",
    "                                  dim=-1)\n",
    "        \n",
    "        # -----------------------  Enhancement of local inference information ---------------------#\n",
    "         \n",
    "\n",
    "        # -----------------------   the compositon layer  ---------------------#\n",
    "        # projected_query [B, L, H]\n",
    "        # projected_doc [B, R, H]\n",
    "        projected_query = self.projection(enhanced_query)\n",
    "        projected_doc = self.projection(enhanced_doc)\n",
    "        \n",
    "        # projected_query [B, L, H]\n",
    "        # projected_doc [B, R, H]\n",
    "        query = self.composition(projected_query)\n",
    "        doc = self.composition(projected_doc)\n",
    "        # -----------------------   the compositon layer  ---------------------#\n",
    "\n",
    "        # -----------------------   Pooling  ---------------------#\n",
    "        # query_mask， doc_mask. 判断 query，doc中的每一个数是不是0， 是1则表示该位置是pad\n",
    "        # reverse_query_mask 0的位置代表pad\n",
    "        # reverse_query_mask [B, L]\n",
    "        # reverse_doc_mask [B, R]\n",
    "        reverse_query_mask = 1. - query_mask.float()\n",
    "        reverse_doc_mask = 1. - doc_mask.float()\n",
    "\n",
    "        query_avg = torch.sum(query * reverse_query_mask.unsqueeze(2),dim=1)/ (torch.sum(reverse_query_mask, dim=1, keepdim=True) + 1e-8)\n",
    "        doc_avg = torch.sum(doc * reverse_doc_mask.unsqueeze(2),dim=1)/ (torch.sum(reverse_doc_mask, dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # 防止取出pad\n",
    "        query = query.masked_fill(query_mask.unsqueeze(2), -1e7)\n",
    "        doc = doc.masked_fill(doc_mask.unsqueeze(2), -1e7)\n",
    "        \n",
    "        \n",
    "        query_max, _ = query.max(dim=1)\n",
    "        doc_max, _ = doc.max(dim=1)\n",
    "        \n",
    "        # v [B, 4*H]\n",
    "        v = torch.cat([query_avg, query_max, doc_avg, doc_max], dim=-1)\n",
    "        # -----------------------   Pooling  ---------------------#\n",
    "\n",
    "        # -----------------------   prediction  ---------------------#\n",
    "        # hidden [B, H]\n",
    "        hidden = self.classification(v)\n",
    "\n",
    "        out = self.out(hidden)\n",
    "        outputs = (out, )\n",
    "        # -----------------------   prediction  ---------------------#\n",
    "\n",
    "        if len(inputs) == 3:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(out, inputs[-1])\n",
    "            outputs = (loss, ) + outputs\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![attention3](https://img-blog.csdnimg.cn/20210708201252776.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attention计算过程：\n",
    "1. 将文本转为embeddings\n",
    "2. 使用embedding分别与三个矩阵（Wq, Wk, Wv）想乘， 得到q,k,v\n",
    "3. 为每个embedding计算一个score, score=q.k\n",
    "4. 除以 根号 dk\n",
    "5. 对 v 加权平均（softmax, sum）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "def train(config, id2label, train_dataloader, val_dataloader):\n",
    "    # ---------------------- part 1 ---------------------- #\n",
    "    # 配置文件\n",
    "    bert_config = BertConfig.from_pretrained(config['model_path'])\n",
    "    bert_config.num_labels = len(id2label)\n",
    "    model = BertForSequenceClassification.from_pretrained(config['model_path'], config=bert_config)\n",
    "    # ---------------------- part 1 ---------------------- #\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20210709132851125.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NeZha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![NeZha1](https://img-blog.csdnimg.cn/20210708204825728.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "NeZha对于BERT的改进 \\\n",
    "函数式相对位置编码、全词掩码、混合精度训练和LAMB优化器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![NeZha2](https://img-blog.csdnimg.cn/20210708205133810.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 混合精度训练\n",
    "作用：训练时，尽量不降低性能，并提升速度\n",
    "Float16优点:\n",
    "* 减少内存的使用\n",
    "* 加快训练和推断的计算，能带来多一倍速的体验\n",
    "\n",
    "Float16缺点:\n",
    "* 溢出错误\n",
    "* 舍入误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![amp2](https://img-blog.csdnimg.cn/72b642b508024cc2a6207c308347c7e7.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "当进入autocast()时， 系统自动切换为float16, autocast上下文只包含前向传播，建议不用反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![scaling](https://img-blog.csdnimg.cn/bbae5cdd360748ecb59cee8dc6f728f2.png?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* scaler.scale(loss) 将给定的损失成一缩放器的当前比例因子，进行反向传播\n",
    "* scaler.step(optimizer) 取消缩放梯度并调用optimizer.step()\n",
    "* scaler.update() 更新缩放器的比例因子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![example](https://img-blog.csdnimg.cn/dfeebde4d34b496096062bb7dbbee7b6.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Momentum\n",
    "* Adagrad\n",
    "* Adam\n",
    "* AdamW\n",
    "* Lookahead\n",
    "* Lamb\n",
    "* WarmUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* cross-entropy\n",
    "* KLDIV\n",
    "* MSE\n",
    "* Label smoothing\n",
    "* Focal loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对抗训练方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![对抗训练](https://img-blog.csdnimg.cn/20210716113626200.png?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对抗训练方法\n",
    "### Fast Gradient Method(FGM)\n",
    "### Projected Gradient Descent(PGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## FGM\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r\n",
    "3. 计算x+r的前向loss, 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "4. 将embedding恢复为（1）时的embedding；\n",
    "5. 根据（3）的梯度对参数进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PGD\n",
    "FGM是一下子算出了对抗扰动，这样得到的扰动不一定是最优的。因此PGD进行了改进，多迭代了K/t次，慢慢找到最优的扰动\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "  对于每步t：\n",
    "  2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r；\n",
    "  3. t如果不是最后一步，将梯度归0， 根据2的x+r计算前后向并得到梯度\n",
    "  4. t是最后一步，恢复1的梯度，计算最后的x+r并将梯度累加到(1)上\n",
    "5. 将embedding恢复为（1）时的embedding；\n",
    "6.根据（4）的梯度对参数进行更新。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
